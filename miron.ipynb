{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1acf78a",
   "metadata": {
    "id": "b1acf78a"
   },
   "source": [
    "# Глубинное обучение для текстовых данных, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 2: Рекуррентные нейронные сети\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — __10 (+3) баллов__. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Весь код должен быть написан самостоятельно. Чужим кодом для пользоваться запрещается даже с указанием ссылки на источник. В разумных рамках, конечно. Взять пару очевидных строчек кода для реализации какого-то небольшого функционала можно.\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "__Мягкий дедлайн: 5.10.25 23:59__   \n",
    "__Жесткий дедлайн: 8.10.25 23:59__\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит самостоятельно реализовать модель LSTM для решения задачи классификации с пересекающимися классами (multi-label classification). Это вид классификации, в которой каждый объект может относиться одновременно к нескольким классам. Такая задача часто возникает при классификации фильмов по жанрам, научных или новостных статей по темам, музыкальных композиций по инструментам и так далее.\n",
    "\n",
    "В нашем случае мы будем работать с датасетом биотехнических новостей и классифицировать их по темам. Этот датасет уже предобработан: текст приведен к нижнему регистру, удалена пунктуация, все слова разделены проблелом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1a5fff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "af1a5fff",
    "outputId": "891c58cd-6964-4319-ade3-92bb90356f93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive your plow over the bones of the dead by ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the recently tabled national budget denel h...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shares take a break its good for you picture g...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reso is currently hiring for two positions pro...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charter buyer club what is the charter buyer c...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0  drive your plow over the bones of the dead by ...  other\n",
       "1  in the recently tabled national budget denel h...  other\n",
       "2  shares take a break its good for you picture g...  other\n",
       "3  reso is currently hiring for two positions pro...  other\n",
       "4  charter buyer club what is the charter buyer c...  other"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('data/biotech_news.tsv', sep='\\t')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a128f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drive your plow over the bones of the dead by olga tokarczuk i am an incredibly slow reader but the tone and specificity of the world she creates in this book was something i couldnt leave behind until it was done also all we sawby anne michaels fight nightby miriam toews and the summer before the darkby doris lessing id like turned into a netflix show by amia srinivasan one of the most brain shattering books ive ever read her thinking is so electrically rigorous and fearless i double dare them to make this into a netflix show i last bought i rediscovered her poetry lately and i feel like i dont want to read anything else for a while she owns desire and submerged things has the greatest ending by j d salinger the last page always leaves me breathless the intimacy and truth of that final page is so arresting and almost painful to read should be on every college syllabus by anton piatigorsky a fascinating fictional account of the adolescence of dictators it is painstakingly researched and so imaginative he takes on whole histories through a small specific human lens ive re read the most gilead by marilynne robinson it reminds me of the wild depths of kindness humans are capable of it helps me get to sleep when im agitated it is so incredibly gentle complex wise and hopeful it gives me a glimpse into what faith can feel like that holds the recipe to a favorite dish marcella hazans tomato butter onion sauce from essentials of classic italian cooking i discovered it when i was 17 no matter how much i cook ive never found anything that matches the pure magic of what these three simple ingredients do together bonus question if i could live in any library or bookstore in the world it would be'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HRBZwYd9QMMS",
   "metadata": {
    "id": "HRBZwYd9QMMS"
   },
   "source": [
    "## Предобработка лейблов\n",
    "\n",
    "\n",
    "__Задание 1 (0.5 балла)__. Как вы можете заметить, лейблы записаны в виде строк, разделенных запятыми. Для работы с ними нам нужно преобразовать их в числа. Так как каждый объект может принадлежать нескольким классам, закодируйте лейблы в виде векторов из 0 и 1, где 1 означает, что объект принадлежит соответствующему классу, а 0 – не принадлежит. Имея такую кодировку, мы сможем обучить модель, решая задачу бинарной классификации для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c65a9bf-dbe9-4cad-978d-3a0e10b1eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = dataset['labels'].apply(lambda s: [t.strip() for t in s.split(',') if t.strip()])\n",
    "C = sorted({t for L in ls for t in L})\n",
    "c2i = {t:i for i,t in enumerate(C)}\n",
    "\n",
    "Y = np.zeros((len(ls), len(C)), dtype=np.float32)\n",
    "for i,L in enumerate(ls):\n",
    "    for t in L:\n",
    "        Y[i, c2i[t]] = 1.0\n",
    "X = dataset['text'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0296f-9699-475e-b4bd-c9e531dca2d4",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vMe0c5AAXM8d",
   "metadata": {
    "id": "vMe0c5AAXM8d"
   },
   "source": [
    "В этом задании мы будем обучать рекуррентные нейронные сети. Как вы знаете, они работают лучше для коротких текстов, так как не очень хорошо улавливают далекие зависимости. Для уменьшение длин текстов их стоит почистить.\n",
    "\n",
    "Сразу разделим выборку на обучающую и тестовую, чтобы считать все нужные статистики только по обучающей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8135000",
   "metadata": {
    "id": "f8135000"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace679c-db5f-45d3-8fa3-6a5c55eb912a",
   "metadata": {},
   "source": [
    "__Задание 2 (1 балл)__. Удалите из текстов стоп слова, слишком редкие и слишком частые слова. Гиперпараметры подберите самостоятельно (в идеале их стоит подбирать по качеству на тестовой выборке). Если вы считаете, что стоит добавить еще какую-то обработку, то сделайте это. Важно не удалить ничего, что может повлиять на предсказание класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "BcmyCcoaXIqy",
   "metadata": {
    "id": "BcmyCcoaXIqy"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter\n",
    "\n",
    "stop = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "def tok(s): \n",
    "    return [w for w in s.split() if w]\n",
    "\n",
    "def clean(s): \n",
    "    return [w for w in tok(s) if w in ok]\n",
    "\n",
    "df = Counter()\n",
    "for s in texts_train: \n",
    "    df.update(set(tok(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86727b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19249 ['levante', 'sullivanfrom', 'analystsofficially', '639', 'andria', 'header', 'rw00014506193', 'overtook', 'aliases', 'rxis', 'newcomer', 'notwithstanding', '3trn', 'logjam', 'eleadora', 'laments', 'lm', 'delitunan', 'courtenay', 'diffusers', 'fedohas', 'auntie', 'encoded', 'wineries', 'startengine', 'ontogeny', 'kuerponan', 'bcbst', 'cancels', 'bushy', 'psychophysics', 'myt', 'touc', 'grading', 'booms', 'sigwart', 'interns', 'greenwashed', '2835', 'macrotra', 'smythe', 'lister', 'lyndsey', 'kpop', 'mikhail', 'cottonmouthsis', 'mikhaylovich', 'sidestep', 'quad', 'splend', 'alpro', 'unwelcoming', 'reciprocity', 'tereno', 'ventilatory', 'ians', 'moderno', 'energizer', 'aym', 'honorable', 'sanjiv', 'fisted', 'vodka', 'scripture', 'percelen', 'starwood', 'connor', 'itukraine', '1416', 'oligopoly', 'slurs', 'skyscraper', 'blues', 'barcelonas', 'clutches', 'bixby', 'falk', 'nortis', 'nursesto', 'alkeon', 'corzine', 'categorys', 'millionchildrenhave', 'chinking', 'blakely', 'glovis', 'captivated', 'hinge', 'arjo', 'compensating', 'terriers', 'multipleyears', 'millionfor', 'eras', 'firex', 'enverus', 'recognises', 'deckersreported', 'koonsman', 'thurles']\n",
      "15 ['a', 'the', 'in', 'at', 'that', 'on', 'to', 'for', 'has', 'as', 'is', 'by', 'of', 'with', 'and']\n"
     ]
    }
   ],
   "source": [
    "min_df = 2\n",
    "rare_words = {w for w, c in df.items() if c < min_df}\n",
    "print(len(rare_words), list(rare_words)[:100])\n",
    "\n",
    "max_df = 0.75\n",
    "n = len(texts_train)\n",
    "freq_words = {w for w, c in df.items() if c / n > max_df}\n",
    "print(len(freq_words), list(freq_words)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cebe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df, max_df = 2, 0.75\n",
    "ok = {w for w, c in df.items() \n",
    "      if c >= min_df and c/n <= max_df and w not in stop and w.isalpha() and len(w)>1}\n",
    "\n",
    "tr_tok = [clean(s) for s in texts_train]\n",
    "te_tok = [clean(s) for s in texts_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4848c2-7fe1-43f9-8564-1144015fc29b",
   "metadata": {},
   "source": [
    "__Задание 3 (1.5 балла)__. Осталось перевести тексты в индексы токенов, чтобы их можно было подавать в модель. У вас есть две опции, как это сделать:\n",
    "1. __(+0 баллов)__ Токенизировать тексты по словам.\n",
    "2. __(до +3 баллов)__ Реализовать свою токенизацию BPE. Количество баллов будет варьироваться в зависимости от эффективности реализации. При реализации нельзя пользоваться специализированными библиотеками.\n",
    "\n",
    "Токенизируйте тексты, переведите их в списки индексов и сложите вместе с лейблами в `DataLoader`. Не забудьте добавить в `DataLoader` `collate_fn`, которая будет дополнять все короткие тексты в батче паддингами. Для маппинга токенов в индексы вам может пригодиться `gensim.corpora.dictionary.Dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae76939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class BPE:\n",
    "    def __init__(self, vs):\n",
    "        self.vs = vs\n",
    "        self.m = []\n",
    "        self.itos = []\n",
    "        self.stoi = {}\n",
    "        self.pad = '<pad>'\n",
    "        self.unk = '<unk>'\n",
    "\n",
    "    def _merge_seq(self, seq, a, b):\n",
    "        out, i, n, ab = [], 0, len(seq), a + b\n",
    "        while i < n:\n",
    "            if i + 1 < n and seq[i] == a and seq[i+1] == b:\n",
    "                out.append(ab)\n",
    "                i += 2\n",
    "            else:\n",
    "                out.append(seq[i])\n",
    "                i += 1\n",
    "        return out\n",
    "\n",
    "    def _merge_multi(self, seq, pairs):\n",
    "        P = {p: (p[0] + p[1]) for p in pairs}\n",
    "        out, i, n = [], 0, len(seq)\n",
    "        while i < n:\n",
    "            if i + 1 < n:\n",
    "                a, b = seq[i], seq[i+1]\n",
    "                if (a, b) in P:\n",
    "                    out.append(P[(a, b)])\n",
    "                    i += 2\n",
    "                    continue\n",
    "            out.append(seq[i])\n",
    "            i += 1\n",
    "        return out\n",
    "\n",
    "    def fit(self, X):\n",
    "        S = [list(s) for s in X]\n",
    "        base = sorted({ch for s in S for ch in s})\n",
    "        k = max(0, self.vs - 2 - len(base))\n",
    "        self.m = []\n",
    "        done = 0\n",
    "        pbar = tqdm(total=k)\n",
    "        seen = set()\n",
    "        while done < k:\n",
    "            cnt = Counter()\n",
    "            for seq in S:\n",
    "                for a, b in zip(seq, seq[1:]):\n",
    "                    if b != ' ':\n",
    "                        cnt[(a, b)] += 1\n",
    "            if not cnt:\n",
    "                break\n",
    "            want = int(np.sqrt(k - done))\n",
    "            pairs = []\n",
    "            for (a, b), _ in cnt.most_common():\n",
    "                if (a, b) in seen:\n",
    "                    continue\n",
    "                pairs.append((a, b))\n",
    "                if len(pairs) == want:\n",
    "                    break\n",
    "            if not pairs:\n",
    "                break\n",
    "            self.m.extend(pairs)\n",
    "            seen.update(pairs)\n",
    "            S = [self._merge_multi(seq, pairs) for seq in S]\n",
    "            done += len(pairs)\n",
    "            pbar.update(len(pairs))\n",
    "        pbar.close()\n",
    "        self.itos = [self.pad, self.unk] + base + [a + b for a, b in self.m]\n",
    "        self.stoi = {t: i for i, t in enumerate(self.itos)}\n",
    "\n",
    "    def enc(self, s):\n",
    "        seq = list(s)\n",
    "        for a, b in self.m:\n",
    "            seq = self._merge_seq(seq, a, b)\n",
    "        return [self.stoi.get(t, 1) for t in seq]\n",
    "\n",
    "    def enc_batch(self, X):\n",
    "        return [self.enc(s) for s in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91002e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2960/2960 [02:35<00:00, 19.02it/s]\n"
     ]
    }
   ],
   "source": [
    "bpe = BPE(vs=3000)\n",
    "bpe.fit(texts_train)\n",
    "PAD = 0\n",
    "V = len(bpe.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▋                                                                                                                                                    | 163/2431 [00:45<10:13,  3.69it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "Xtr = [bpe.enc(s) for s in tqdm(texts_train)]\n",
    "Xte = [bpe.enc(s) for s in tqdm(texts_test)]\n",
    "\n",
    "class DS(Dataset):\n",
    "    def __init__(self, X, Y): \n",
    "        self.X, self.Y = X, torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        return self.X[i], self.Y[i]\n",
    "\n",
    "MAX_L = 600\n",
    "\n",
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    xs = [x[:MAX_L] for x in xs]\n",
    "    ln = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "    L = int(ln.max())\n",
    "    pad = torch.full((len(xs), L), PAD, dtype=torch.long)\n",
    "    for i,x in enumerate(tqdm(xs, leave=False)):\n",
    "        if x:\n",
    "            pad[i,:len(x)] = torch.tensor(x, dtype=torch.long)\n",
    "    return pad, ln, torch.stack(ys)\n",
    "\n",
    "\n",
    "tr_ds = DS(Xtr, y_train)\n",
    "te_ds = DS(Xte, y_test)\n",
    "\n",
    "tr_dl = DataLoader(\n",
    "    tr_ds, \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate\n",
    ")\n",
    "te_dl = DataLoader(\n",
    "    te_ds, \n",
    "    batch_size=64, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e53652",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    dev = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    dev = torch.device('cuda')\n",
    "else:\n",
    "    dev = torch.device('cpu')\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e78f9-6bef-46f4-8b58-818b7eb0c082",
   "metadata": {},
   "source": [
    "## Метрика качества\n",
    "\n",
    "Перед тем, как приступить к обучению, нам нужно выбрать метрику оценки качества. Так как в задаче классификации с пересекающимися классами классы часто несбалансированы, чаще всего в качестве метрики берется [F1 score](https://en.wikipedia.org/wiki/F-score).\n",
    "\n",
    "Функция `compute_f1` принимает истинные метки и предсказанные и считает среднее значение F1 по всем классам. Используйте ее для оценки качества моделей.\n",
    "\n",
    "$$\n",
    "F1_{total} = \\frac{1}{K} \\sum_{k=1}^K F1(Y_k, \\hat{Y}_k),\n",
    "$$\n",
    "где $Y_k$ – истинные значения для класса k, а $\\hat{Y}_k$ – предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a0928-fd68-4f36-bae7-2dacb18fd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_f1(y_true, y_pred):\n",
    "    assert y_true.ndim == 2\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    return f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "def best_thr(y_true, y_prob, grid=np.linspace(0.05, 0.6, 24)):\n",
    "    f1s = [compute_f1(y_true, (y_prob >= t).astype(np.int32)) for t in grid]\n",
    "    i = int(np.argmax(f1s))\n",
    "    return float(grid[i]), float(f1s[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aagj29J7Ap2H",
   "metadata": {
    "id": "aagj29J7Ap2H"
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae5666",
   "metadata": {
    "id": "56ae5666"
   },
   "source": [
    "### RNN\n",
    "\n",
    "В качестве бейзлайна обучим самую простую рекуррентную нейронную сеть. Напомним, что блок RNN выглядит таким образом.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/yYbNBm6G/tg-image-1635618906.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Его скрытое состояние обновляется по формуле\n",
    "$h_t = \\sigma(W x_{t} + U h_{t-1} + b_h)$. А предсказание считается с помощью применения линейного слоя к последнему токену\n",
    "$o_T = V h_T + b_o$. В качестве функции активации выберите гиперболический тангенс. \n",
    "\n",
    "__Задание 4 (2 балла)__. Реализуйте RNN в соответствии с формулой выше и обучите ее на нашу задачу. Нулевой скрытый вектор инициализируйте нулями, так модель будет обучаться стабильнее, чем при случайной инициализации. После этого замеряйте качество на тестовой выборке. У вас должно получиться значение F1 не меньше 0.33, а само обучение не должно занимать много времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05743f95-dd39-43f5-81cf-1a79edc194fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, V, E, H, O, pad=0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(V, E, padding_idx=pad)\n",
    "        self.W = nn.Linear(E, H, bias=True)\n",
    "        self.U = nn.Linear(H, H, bias=False)\n",
    "        self.o = nn.Linear(H, O)\n",
    "\n",
    "    def forward(self, x, ln):\n",
    "        e = self.emb(x)\n",
    "        B,T,_ = e.shape\n",
    "        h = torch.zeros(B, self.U.out_features, device=e.device)\n",
    "        Hs = []\n",
    "        for t in range(T):\n",
    "            h = torch.tanh(self.W(e[:,t]) + self.U(h))\n",
    "            Hs.append(h)\n",
    "        Hs = torch.stack(Hs, 1)\n",
    "        idx = (ln-1).view(-1,1,1).expand(-1,1,Hs.size(-1))\n",
    "        last = Hs.gather(1, idx).squeeze(1)\n",
    "        return self.o(last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = torch.tensor((y_train.shape[0] - y_train.sum(0)) / (y_train.sum(0) + 1e-6), dtype=torch.float32, device=dev)\n",
    "\n",
    "def fit(m, tr, te, ep=10, lr=3e-3, wd=1e-5, l1_w=1e-5, clip=1.0, pos_weight=None):\n",
    "    m.to(dev)\n",
    "    crit = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=lr, weight_decay=wd)  # wd это L2\n",
    "    \n",
    "    for e in range(ep):\n",
    "        m.train()\n",
    "        tot, n = 0.0, 0\n",
    "        pbar = tqdm(tr, desc=f'train {e+1}/{ep}', leave=False)\n",
    "        for xb, lb, yb in pbar:\n",
    "            xb, lb, yb = xb.to(dev), lb.to(dev), yb.to(dev)\n",
    "            opt.zero_grad()\n",
    "            z = m(xb, lb)\n",
    "            main_loss = crit(z, yb)\n",
    "            \n",
    "            l1_loss = 0.0\n",
    "            if l1_w > 0:\n",
    "                for param in m.parameters():\n",
    "                    l1_loss += torch.norm(param, 1)\n",
    "            \n",
    "            total_loss = main_loss + l1_w * l1_loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(m.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            bs = xb.size(0)\n",
    "            tot += total_loss.item() * bs\n",
    "            n += bs\n",
    "            pbar.set_postfix(loss=f'{tot/n:.4f}')\n",
    "        \n",
    "        m.eval()\n",
    "        yp, yt = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, lb, yb in te:\n",
    "                xb, lb = xb.to(dev), lb.to(dev)\n",
    "                p = torch.sigmoid(m(xb, lb)).cpu().numpy()\n",
    "                yp.append(p)\n",
    "                yt.append(yb.numpy().astype(np.int32))\n",
    "        yp = np.vstack(yp)\n",
    "        yt = np.vstack(yt)\n",
    "        thr, f1 = best_thr(yt, yp)\n",
    "        print(f'ep {e+1:02d} thr {thr:.3f} f1 {f1:.4f}')\n",
    "    \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4093a595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 1/30:   0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 01 thr 0.480 f1 0.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 02 thr 0.480 f1 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 03 thr 0.504 f1 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 04 thr 0.457 f1 0.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 05 thr 0.528 f1 0.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 06 thr 0.552 f1 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 07 thr 0.600 f1 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 08 thr 0.600 f1 0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 09 thr 0.600 f1 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10 thr 0.552 f1 0.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11 thr 0.600 f1 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12 thr 0.600 f1 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13 thr 0.552 f1 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14 thr 0.600 f1 0.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15 thr 0.600 f1 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16 thr 0.600 f1 0.2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17 thr 0.576 f1 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18 thr 0.600 f1 0.2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19 thr 0.600 f1 0.2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20 thr 0.600 f1 0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21 thr 0.600 f1 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22 thr 0.600 f1 0.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23 thr 0.600 f1 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24 thr 0.528 f1 0.2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25 thr 0.600 f1 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26 thr 0.600 f1 0.2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27 thr 0.600 f1 0.2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28 thr 0.600 f1 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29 thr 0.600 f1 0.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30 thr 0.600 f1 0.2591\n"
     ]
    }
   ],
   "source": [
    "E, H = 64, 128\n",
    "rnn = RNN(V, E, H, y_train.shape[1], pad=PAD)\n",
    "rnn = fit(rnn, tr_dl, te_dl, ep=30, pos_weight=pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xqt0dk6LEJUU",
   "metadata": {
    "id": "xqt0dk6LEJUU"
   },
   "source": [
    "### LSTM\n",
    "\n",
    "<img src=\"https://i.postimg.cc/pL5LdmpL/tg-image-2290675322.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Теперь перейдем к более продвинутым рекурренным моделям, а именно LSTM. Из-за дополнительного вектора памяти эта модель должна гораздо лучше улавливать далекие зависимости, что должно напрямую отражаться на качестве.\n",
    "\n",
    "Параметры блока LSTM обновляются вот так ($\\sigma$ означает сигмоиду):\n",
    "\\begin{align}\n",
    "f_{t} &= \\sigma(W_f x_{t} + U_f h_{t-1} + b_f) \\\\ \n",
    "i_{t} &= \\sigma(W_i x_{t} + U_i h_{t-1} + b_i) \\\\\n",
    "\\tilde{c}_{t} &= \\tanh(W_c x_{t} + U_c h_{t-1} + b_i) \\\\\n",
    "c_{t} &= f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t \\\\\n",
    "o_{t} &= \\sigma(W_t x_{t} + U_t h_{t-1} + b_t) \\\\\n",
    "h_t &= o_t \\odot \\tanh(c_t)\n",
    "\\end{align}\n",
    "\n",
    "__Задание 5 (2 балла).__ Реализуйте LSTM по описанной схеме. Выберите гиперпараметры LSTM так, чтобы их общее число (без учета слоя эмбеддингов) примерно совпадало с числом параметров обычной RNN, но размерность скрытого слоя была не меньше 64. Так мы будем сравнивать архитектуры максимально независимо. Обучите LSTM до сходимости и сравните качество с RNN на тестовой выборке. Удалось ли получить лучший результат? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e18b79b-f2c6-4474-a5c0-c8ce51f13afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, I, H):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(I, 4*H, bias=True)\n",
    "        self.U = nn.Linear(H, 4*H, bias=False)\n",
    "        self.H = H\n",
    "    def forward(self, x, h, c):\n",
    "        g = self.W(x) + self.U(h)\n",
    "        f,i,gc,o = torch.chunk(g, 4, -1)\n",
    "        f,i,o = torch.sigmoid(f), torch.sigmoid(i), torch.sigmoid(o)\n",
    "        gc = torch.tanh(gc)\n",
    "        c = f*c + i*gc\n",
    "        h = o*torch.tanh(c)\n",
    "        return h,c\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, V, E, H, O, pad=0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(V, E, padding_idx=pad)\n",
    "        self.cell = LSTMCell(E, H)\n",
    "        self.o = nn.Linear(H, O)\n",
    "        self.H = H\n",
    "    def forward(self, x, ln):\n",
    "        e = self.emb(x)\n",
    "        B,T,_ = e.shape\n",
    "        h = torch.zeros(B, self.H, device=e.device)\n",
    "        c = torch.zeros(B, self.H, device=e.device)\n",
    "        Hs = []\n",
    "        for t in range(T):\n",
    "            h,c = self.cell(e[:,t], h, c)\n",
    "            Hs.append(h)\n",
    "        Hs = torch.stack(Hs,1)\n",
    "        idx = (ln-1).view(-1,1,1).expand(-1,1,self.H)\n",
    "        last = Hs.gather(1, idx).squeeze(1)\n",
    "        return self.o(last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f9d8f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 01 thr 0.480 f1 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 02 thr 0.457 f1 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 03 thr 0.457 f1 0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 04 thr 0.504 f1 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 05 thr 0.433 f1 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 06 thr 0.552 f1 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 07 thr 0.600 f1 0.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 08 thr 0.600 f1 0.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 09 thr 0.600 f1 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10 thr 0.600 f1 0.2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11 thr 0.600 f1 0.2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12 thr 0.600 f1 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13 thr 0.600 f1 0.2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14 thr 0.600 f1 0.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15 thr 0.600 f1 0.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16 thr 0.600 f1 0.2561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17 thr 0.504 f1 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18 thr 0.600 f1 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19 thr 0.600 f1 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20 thr 0.600 f1 0.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21 thr 0.576 f1 0.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22 thr 0.600 f1 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23 thr 0.600 f1 0.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24 thr 0.504 f1 0.2841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25 thr 0.600 f1 0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26 thr 0.600 f1 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27 thr 0.600 f1 0.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28 thr 0.600 f1 0.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29 thr 0.528 f1 0.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30 thr 0.600 f1 0.2866\n"
     ]
    }
   ],
   "source": [
    "H2 = 112\n",
    "lstm = LSTM(V, E, H2, y_train.shape[1], pad=PAD)\n",
    "lstm = fit(lstm, tr_dl, te_dl, ep=30, pos_weight=pw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdd1a1-51f4-4065-85f7-22ed773a2628",
   "metadata": {},
   "source": [
    "__Задание 6 (2 балла).__ Главный недостаток RNN моделей заключается в том, что при сжатии всей информации в один вектор, важные детали пропадают. Для решения этой проблемы был придуман механизм внимания. Реализуйте его по [оригинальной статье](https://arxiv.org/abs/1409.0473). Замерьте качество и сделайте выводы.   \n",
    "Обратите внимание, что метод был предложен для Encoder-Decoder моделей. В нашем случае декодера нет, поэтому встройте внимание в энкодер: каждый блок LSTM будет смотреть на выходы всех предыдущих блоков.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5bd1fa9-2c1f-4268-be24-5c31752204ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMA(nn.Module):\n",
    "    def __init__(self, V, E, H, O, pad=0):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(V, E, padding_idx=pad)\n",
    "        self.cell = LSTMCell(E, H)\n",
    "\n",
    "        self.Wk = nn.Linear(H, H, bias=False)\n",
    "        self.Wq = nn.Linear(H, H, bias=False)\n",
    "        self.v = nn.Linear(H, 1, bias=False)\n",
    "\n",
    "        self.Wc = nn.Linear(2*H, H)\n",
    "        self.o = nn.Linear(H, O)\n",
    "        self.H = H\n",
    "        \n",
    "    def forward(self, x, ln):\n",
    "        e = self.emb(x)\n",
    "        B,T,_ = e.shape\n",
    "        h = torch.zeros(B, self.H, device=e.device)\n",
    "        c = torch.zeros(B, self.H, device=e.device)\n",
    "        Hs = []\n",
    "        for t in range(T):\n",
    "            h,c = self.cell(e[:,t], h, c)\n",
    "            Hs.append(h)\n",
    "        H = torch.stack(Hs,1)\n",
    "        idx = (ln-1).clamp_min(0).view(-1,1,1).expand(-1,1,self.H)\n",
    "        hT = H.gather(1, idx).squeeze(1)\n",
    "        K = self.Wk(H)\n",
    "        q = self.Wq(hT).unsqueeze(1)\n",
    "        s = self.v(torch.tanh(K + q)).squeeze(-1)\n",
    "        mask = (torch.arange(T, device=e.device).unsqueeze(0) >= ln.unsqueeze(1))\n",
    "        s = s.masked_fill(mask, float('-inf'))\n",
    "        a = torch.softmax(s, -1)\n",
    "        ctx = (a.unsqueeze(-1) * H).sum(1)\n",
    "        h_ = torch.tanh(self.Wc(torch.cat([hT, ctx], -1)))\n",
    "        return self.o(h_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0d04dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 01 thr 0.480 f1 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 02 thr 0.480 f1 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 03 thr 0.504 f1 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 04 thr 0.480 f1 0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 05 thr 0.528 f1 0.1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 06 thr 0.552 f1 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 07 thr 0.600 f1 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 08 thr 0.552 f1 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 09 thr 0.600 f1 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10 thr 0.600 f1 0.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11 thr 0.600 f1 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12 thr 0.600 f1 0.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13 thr 0.552 f1 0.2766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14 thr 0.600 f1 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15 thr 0.600 f1 0.2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16 thr 0.600 f1 0.2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17 thr 0.600 f1 0.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18 thr 0.600 f1 0.2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19 thr 0.552 f1 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20 thr 0.600 f1 0.2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21 thr 0.600 f1 0.3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22 thr 0.600 f1 0.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23 thr 0.600 f1 0.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24 thr 0.600 f1 0.3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25 thr 0.600 f1 0.3149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26 thr 0.600 f1 0.3206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27 thr 0.600 f1 0.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28 thr 0.600 f1 0.3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29 thr 0.600 f1 0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30 thr 0.600 f1 0.3473\n"
     ]
    }
   ],
   "source": [
    "lstm_a = LSTMA(V, E, H2, y_train.shape[1], pad=PAD)\n",
    "lstm_a = fit(lstm_a, tr_dl, te_dl, ep=30, pos_weight=pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phQ-ka4mp0oS",
   "metadata": {
    "id": "phQ-ka4mp0oS"
   },
   "source": [
    "__Задание 7 (1 балл).__ Добавьте в вашу реализации возможность увеличивать число слоев LSTM. Обучите модель с двумя слоями и замерьте качество. Сделайте выводы: стоит ли увеличивать размер модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c7177",
   "metadata": {
    "id": "ee7c7177"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c0d7e7",
   "metadata": {},
   "source": [
    "Лень модифицировать, но мое предположение в том, что на таком маленьком датасете увеличение размера модели скорее увеличит риск переобучения, а не качество. Хотя, конечно, если запариться, можно немного улучшить качество. Наверняка, случайно выбранные параметры не самые оптимальные."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12b0627d4aaf46c0adc64b442bf88d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d5b2e090c51406e953b4eec4b0b91ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "282f83858a424e2ea76990eb957dc5a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32808478ae8c4242beb79f0272ea6b1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e8d1401c0e4dc1a8e71bbad7c2f74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b23f3b8b7247491c8d5e3ead7f54d886",
      "placeholder": "​",
      "style": "IPY_MODEL_cb632291897f4f9db86a00a5a71ca35f",
      "value": " 40/40 [36:41&lt;00:00, 51.61s/it]"
     }
    },
    "3735627f227d4b4f927955113111409f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f4f11bc6984b96ac3c3875d733f0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc4f687f9d5940aba074e2bb41581c93",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e10fd6d1a6c47a9ac34a47ae5ba708b",
      "value": 40
     }
    },
    "4aab16bb20824688aadbd23460adad9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f65eec1b45de42e59fb9e24b99aad917",
       "IPY_MODEL_47f4f11bc6984b96ac3c3875d733f0ba",
       "IPY_MODEL_f58fddb1bf414071b0523701a619ad71"
      ],
      "layout": "IPY_MODEL_32808478ae8c4242beb79f0272ea6b1f"
     }
    },
    "4de9492961d841aa9f3d7bc629911296": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67ae0c089c4a426db3b52976fae1a9dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e10fd6d1a6c47a9ac34a47ae5ba708b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b23f3b8b7247491c8d5e3ead7f54d886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc4165ff8fc3480fb1590b6ecd39fb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cba16e32a9df4b1b89b4f7066945fc42",
       "IPY_MODEL_e8f0522f19c44066b5a78ded999f050a",
       "IPY_MODEL_34e8d1401c0e4dc1a8e71bbad7c2f74d"
      ],
      "layout": "IPY_MODEL_282f83858a424e2ea76990eb957dc5a0"
     }
    },
    "cb632291897f4f9db86a00a5a71ca35f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cba16e32a9df4b1b89b4f7066945fc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67ae0c089c4a426db3b52976fae1a9dc",
      "placeholder": "​",
      "style": "IPY_MODEL_12b0627d4aaf46c0adc64b442bf88d0a",
      "value": "100%"
     }
    },
    "d7ed88f49793494bbdb3c2fffc01b216": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc4f687f9d5940aba074e2bb41581c93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7876fd73da349ea873c137c63d8d528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8f0522f19c44066b5a78ded999f050a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4de9492961d841aa9f3d7bc629911296",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7876fd73da349ea873c137c63d8d528",
      "value": 40
     }
    },
    "f58fddb1bf414071b0523701a619ad71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d5b2e090c51406e953b4eec4b0b91ad",
      "placeholder": "​",
      "style": "IPY_MODEL_3735627f227d4b4f927955113111409f",
      "value": " 40/40 [1:08:10&lt;00:00, 102.17s/it]"
     }
    },
    "f65eec1b45de42e59fb9e24b99aad917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f67dc08a01ac40ad98ed553fe6b7e948",
      "placeholder": "​",
      "style": "IPY_MODEL_d7ed88f49793494bbdb3c2fffc01b216",
      "value": "100%"
     }
    },
    "f67dc08a01ac40ad98ed553fe6b7e948": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
